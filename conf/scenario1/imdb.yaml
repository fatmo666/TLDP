dataset: imdb
dataset_type: text
batch_size: 64
#noise_type: privacy
noise_type: none
noise_level: 0.1
model: bilstm
model_path: bilstm_model.pth
vocab_size: 25000
embedding_dim: 100
hidden_dim: 128
output_dim: 1
n_layers: 2
bidirectional: True
dropout: 0.3
learning_rate: 0.001
num_classes: 2
num_epochs: 1
loss_function: bce_with_logits
privacy_function: laplace
epsilon: 0.01
sensitivity: 2
target_float: False
multi_targets: False